{"cells":[{"cell_type":"markdown","source":["# üìä Microsoft Fabric Monitoring Notebook\n","\n","This notebook automates the collection of runtime metadata for key Fabric artifacts:\n","\n","- **Semantic Models**: via Power BI REST API\n","- **Data Pipelines**: via Microsoft Fabric REST API\n","\n","The results are consolidated and stored in a **Delta Lake table**, enabling performance and error trend monitoring across workspaces.\n","\n","## üîç Functionality\n","\n","- Authenticates using `notebookutils.credentials.getToken('pbi')`\n","- Iterates through all available Fabric workspaces\n","- Collects run metadata for:\n","  - **Semantic Models** (last refresh via Power BI)\n","  - **Data Pipelines** (last run via Fabric Job Scheduler)\n","- Outputs to: `dbo.item_runs` (Delta Lake table)\n","\n","Links used:\n","  - **Semantic Models**: [Get Refresh History](https://learn.microsoft.com/en-us/rest/api/power-bi/datasets/get-refresh-history)\n","  - **Data Pipelines**: [List Item Job Instances](https://learn.microsoft.com/en-us/rest/api/fabric/core/job-scheduler/list-item-job-instances)\n","  - **Workspace List**: [List Workspaces](https://learn.microsoft.com/en-us/rest/api/fabric/core/workspaces/list-workspaces)\n","  - **Workspace Items**: [List Items in a Workspace](https://learn.microsoft.com/en-us/rest/api/fabric/core/items/list-items)\n","\n","## üßæ Output Schema\n","\n","The Delta table (`dbo.item_runs`) has the following schema:\n","\n","| Column                 | Type      | Description                           |\n","|------------------------|-----------|---------------------------------------|\n","| `workspace_name`       | string    | Fabric workspace name                 |\n","| `workspace_id`         | string    | Fabric workspace GUID                 |\n","| `item_type`            | string    | Type: `SemanticModel` or `DataPipeline` |\n","| `item_name`            | string    | Display name of the item              |\n","| `item_id`              | string    | GUID of the item                      |\n","| `last_run_date_time`   | timestamp | Time of most recent run/refresh       |\n","| `last_run_duration_ms` | long      | Duration in milliseconds              |\n","| `last_run_status`      | string    | Status: `Completed`, `Failed`, etc.   |\n","| `is_error`             | int       | 1 if run failed, 0 otherwise          |\n","| `last_run_request_id`  | string    | Unique request ID from the API        |\n","\n","\n","> Use this notebook for scheduled or on-demand diagnostics in your Fabric platform.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f750dadd-a053-4ec2-baa6-1fdc2849a283"},{"cell_type":"code","source":["item_runs_table_name = 'dbo.item_runs'\n","data_pipelines_table_name = 'dbo.data_pipeline_status'\n","monitored_item_types = ['SemanticModel', 'DataPipeline']\n","\n","access_token = notebookutils.credentials.getToken('pbi')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30061753-811c-4133-b069-8b0936347977"},{"cell_type":"code","source":["\n","from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, IntegerType\n","from datetime import datetime\n","\n","schema = StructType([\n","    StructField(\"workspace_name\", StringType(), True),\n","    StructField(\"workspace_id\", StringType(), True),\n","    StructField(\"item_type\", StringType(), True),\n","    StructField(\"item_name\", StringType(), True),\n","    StructField(\"item_id\", StringType(), True),\n","    StructField(\"last_run_date_time\", TimestampType(), True),\n","    StructField(\"last_run_duration_ms\", LongType(), True),\n","    StructField(\"last_run_status\", StringType(), True),\n","    StructField(\"is_error\", IntegerType(), True),\n","    StructField(\"last_run_request_id\", StringType(), True)\n","])\n","\n","items_history = []"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"40974280-3dc5-4871-a258-3f5a6b72e1f8"},{"cell_type":"code","source":["import requests\n","\n","def call_fabric_api(url):\n","    # Set headers with authorization\n","    headers = {\n","        \"Authorization\": f\"Bearer {access_token}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","    # Make the GET request\n","    response = requests.get(url, headers=headers)\n","\n","    try:\n","        data = response.json()\n","    except ValueError:\n","        print(f\"Error: Unable to parse JSON. Status: {response.status_code}, Response: {response.text}\")\n","        print(f\"Url: {url}\")\n","        return\n","\n","    # Check response code\n","    if response.status_code != 200:        \n","        print(f\"Error or unexpected response format. Status: {response.status_code}, Response: {data}\")\n","        return\n","        \n","    # Check if 'value' exists and is a list\n","    if isinstance(data.get(\"value\"), list):\n","        return data[\"value\"]\n","    else:\n","        return data\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0844e3d8-f6fe-4484-8f4e-dc13c00bb634"},{"cell_type":"code","source":["def process_item_run(workspace_name, workspace_id, item_name, item_id, item_type, url_template, time_fields, id_field):\n","    url = url_template.format(workspace_id=workspace_id, item_id=item_id)\n","    run_history = call_fabric_api(url)\n","\n","    if not run_history:\n","        print(f\"‚ö†Ô∏è No run history found for {item_name} ({item_type}) in {workspace_name}\")\n","        return {\n","            \"workspace_name\": workspace_name,\n","            \"workspace_id\": workspace_id,\n","            \"item_type\": item_type,\n","            \"item_name\": item_name,\n","            \"item_id\": item_id,\n","            \"last_run_date_time\": None,\n","            \"last_run_duration_ms\": None,\n","            \"last_run_status\": None,\n","            \"is_error\": None,\n","            \"last_run_request_id\": None\n","        }\n","\n","    run = run_history[0]\n","    start_key, end_key = time_fields\n","\n","    start_time = datetime.fromisoformat(run[start_key])\n","    end_time = datetime.fromisoformat(run[end_key]) if run.get(end_key) else None\n","    duration_ms = int((end_time - start_time).total_seconds() * 1000) if end_time else None\n","    status = run.get(\"status\", \"In Progress\")\n","\n","    return {\n","        \"workspace_name\": workspace_name,\n","        \"workspace_id\": workspace_id,\n","        \"item_type\": item_type,\n","        \"item_name\": item_name,\n","        \"item_id\": item_id,\n","        \"last_run_date_time\": end_time,\n","        \"last_run_duration_ms\": duration_ms,\n","        \"last_run_status\": status,\n","        \"is_error\": 1 if status == \"Failed\" else 0,\n","        \"last_run_request_id\": run.get(id_field)\n","    }\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8b24a15c-ceb1-4005-a064-f20f604635e2"},{"cell_type":"code","source":["# List workspaces\n","workspaces = call_fabric_api(\"https://api.fabric.microsoft.com/v1/workspaces\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e6a4b7d4-b094-43a5-830c-81c924c4b9e8"},{"cell_type":"code","source":["\n","\n","# Loop through workspaces, for each item get runs and save to an array\n","for workspace in workspaces:\n","\n","    workspace_name = workspace['displayName']\n","    workspace_id = workspace['id']\n","\n","    print(f\"üîç Processing workspace: {workspace_name}({workspace_id})\")\n","\n","    # List data items in workspace\n","    items = call_fabric_api(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/items\")\n","\n","    if not items:\n","        print(f\"No items found for workspace {workspace_name} ({workspace_id}).\")\n","        continue\n","\n","\n","    # Build a set of all item names in the workspace excluding SemanticModels and Reports\n","    non_semantic_model_names = {\n","        i['displayName'] for i in items if i['type'] not in {'SemanticModel', 'Report'}\n","    }\n","\n","\n","    # Loop through items and get last run info\n","    for item in items:\n","\n","        item_name = item['displayName']\n","        item_id = item['id']\n","        item_type = item['type']   \n","\n","        # Exclude default semantic models - name must match\n","        if item_type == \"SemanticModel\" and item_name in non_semantic_model_names:\n","            print(f\"Skip default SemanticModel '{item_name}' in {workspace_name} (auto-created)\")\n","            continue\n","             \n","        # Filter only for selected item types\n","        if item_type not in monitored_item_types:\n","            print(f\"Skip:{item_name} in {workspace_name} due to item type{item_type}\")\n","            continue\n","\n","        print(f\"üîç Processing item: {item_name}({item_id}) -Type: {item_type} in workspace: {workspace_name}\")\n","\n","        match item_type:\n","            case \"SemanticModel\":\n","                item_data = process_item_run(\n","                    workspace_name,\n","                    workspace_id,\n","                    item_name,\n","                    item_id,\n","                    item_type,\n","                    url_template=\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{item_id}/refreshes?$top=1\",\n","                    time_fields=(\"startTime\", \"endTime\"),\n","                    id_field=\"requestId\"\n","                )\n","            case \"DataPipeline\":\n","                item_data = process_item_run(\n","                    workspace_name,\n","                    workspace_id,\n","                    item_name,\n","                    item_id,\n","                    item_type,\n","                    url_template=\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/items/{item_id}/jobs/instances\",\n","                    time_fields=(\"startTimeUtc\", \"endTimeUtc\"),\n","                    id_field=\"id\"\n","                )\n","            case _:\n","                log(f\"Skipping {item_name}: unsupported type {item_type}\")\n","                continue\n","\n","\n","        if not item_data:\n","            continue\n","\n","\n","        items_history.append(item_data)\n","    \n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b34380ad-4eac-4c2a-8e68-638af2a4cef8"},{"cell_type":"code","source":["# write to Delta\n","\n","spark.createDataFrame(items_history, schema) \\\n","    .write.mode(\"overwrite\") \\\n","    .option(\"overwriteSchema\", \"true\") \\\n","    .saveAsTable(item_runs_table_name)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a8138b60-4643-4de8-970c-a476427789fa"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"d9898d0e-c2dd-4385-bdf3-249ddcf9cdc5"}],"default_lakehouse":"d9898d0e-c2dd-4385-bdf3-249ddcf9cdc5","default_lakehouse_name":"Fabric_Monitor","default_lakehouse_workspace_id":"d200d34d-2f59-49c6-94fa-374e06e2adda"}}},"nbformat":4,"nbformat_minor":5}